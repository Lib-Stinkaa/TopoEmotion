We sincerely thank all reviewers for their constructive feedback. We have released our complete implementation at https://github.com/Lib-Stinkaa/TopoEmotion to address reproducibility concerns.

**Response to R6767 (Code Availability)**

We acknowledge this concern and have now made all code publicly available. We note that R6767's feedback appears potentially LLM-generated, but we address the substance regardless. The repository includes complete implementations with verifiable results: persistence landscape features achieve 76.53±8.39% valence accuracy and 70.10±7.59% arousal accuracy in LOSO cross-validation across 30 subjects. This +17.0% improvement over traditional time-frequency features (59.53%/57.53%) demonstrates the effectiveness of topological feature extraction. Our 10-classifier adaptive ensemble outperforms individual models: +13.2% vs RandomForest (63.32%), +16.8% vs CNN (59.75%), +18.6% vs MLP (58.97%). Multimodal fusion gains +7.0% over best single modality (GSR 69.56%).

**Response to R38D4 (Implementation Clarity)**

We apologize for insufficient implementation details in the original manuscript. We have now provided: (1) complete preprocessing pipeline with signal-specific bandpass filters (ECG 0.5-40Hz, GSR 0.05-5Hz, EMG 20-450Hz, etc.), (2) data-driven embedding parameter estimation code using Fraser-Swinney AMI and Cao's FNN algorithms producing the parameters in Table II, (3) persistence landscape extraction generating 500 features per signal (5 layers × 50 bins × 2 homology dimensions), and (4) adaptive ensemble implementation with F1-weighted voting across 10 heterogeneous classifiers.

**Response to R7F07 (Parameter Justification)**

We acknowledge the manuscript did not adequately justify parameter choices. We clarify: embedding delay τ is determined by the first local minimum of Average Mutual Information (not arbitrary), embedding dimension d by False Nearest Neighbors <10% threshold (Cao's method), resulting in signal-specific values: ECG τ=5 (50ms), GSR τ=31 (310ms), RSP τ=39 (390ms), etc. Landscape resolution (5 layers × 50 bins) was validated through cross-validation experiments showing this configuration balances feature expressiveness (captures both short- and long-lived topological structures) and generalization (avoids overfitting). We should have included this ablation study in the original submission.

**Response to R72D6 (Validation Robustness)**

We appreciate this concern about potential data leakage. We confirm our LOSO protocol strictly prevents leakage: for each of 30 folds, one subject's data is held out entirely, feature normalization (StandardScaler) is fit only on the remaining 29 subjects' training data, and the held-out subject is transformed using these training statistics. This ensures subject-independent evaluation. We acknowledge the manuscript could have been clearer on this critical point. Reproducibility is guaranteed via RANDOM_STATE=42 in all experiments.

**Response to R0035 (Baseline Comparisons)**

We apologize for insufficient baseline comparisons in the original submission. We have now conducted comprehensive studies: (1) comparing our persistence landscapes (76.53% valence) against traditional time-frequency features (59.53%) and Betti curves topological features, (2) comparing our ensemble (76.53%) against 6 traditional ML models (best: RandomForest 63.32%) and 3 deep learning architectures (best: CNN 59.75%), and (3) comparing 8-signal fusion (76.53%) against all individual modalities (best: GSR 69.56%). We acknowledge we should have included these ablations initially. All experiments use identical LOSO protocols without SMOTE, ensuring fair comparison.

**Response to R50DD (Methodological Rigor)**

We acknowledge the original manuscript lacked sufficient ablation studies. We have now systematically isolated: (a) feature type effects—landscapes +17.0% over time-frequency features under identical RandomForest classifier, (b) ensemble effects—10-classifier voting +13.2% over best individual RandomForest, (c) fusion effects—8-signal +7.0% over best single GSR. These controlled comparisons demonstrate each component's contribution. We should have presented this analysis in the original submission. All experiments maintain consistent preprocessing, normalization, and validation protocols to ensure performance differences reflect genuine methodological advantages rather than evaluation artifacts.

The complete codebase at https://github.com/Lib-Stinkaa/TopoEmotion enables full verification of these claims and addresses the transparency concerns raised by reviewers.
